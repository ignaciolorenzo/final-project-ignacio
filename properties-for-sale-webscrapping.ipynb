{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the most profitable towns in a CCAA given a max price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import nums_from_string as nfs\n",
    "import numpy as np\n",
    "from re import search\n",
    "from random import randint\n",
    "from time import sleep\n",
    "import openpyxl\n",
    "import xlrd\n",
    "import lxml\n",
    "from datetime import datetime, timedelta\n",
    "from collections import Counter\n",
    "import re\n",
    "pd.options.mode.chained_assignment = None\n",
    "import seaborn as sns\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing geo data from csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This enables us to query for a list of towns given an autonomous community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_data = pd.read_csv('/Users/ignaciolorenzoqueralt/Documents/Ironhack/Final Project/data/province-town-n_props/geo-data_2021.10.23.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get input from user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccaa_lst = geo_data['ccaa'].unique().tolist()\n",
    "ccaa = input(\"ccaa: \")\n",
    "while ccaa not in ccaa_lst:\n",
    "    ccaa = input(\"There was no match between your input and our ccaa, try again: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_properties_per_town = \"\"\n",
    "while num_properties_per_town == \"\":\n",
    "    try:\n",
    "        num_properties_per_town = int(input(\"Minimum number of properties per town: \"))\n",
    "    except: \n",
    "        num_properties_per_town = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = geo_data[(geo_data['ccaa'] == ccaa) & (geo_data['n_properties'] > num_properties_per_town)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "maximum price:  90000\n"
     ]
    }
   ],
   "source": [
    "max_price = \"\"\n",
    "while max_price == \"\":\n",
    "    try:\n",
    "        max_price = int(input(\"maximum price: \"))\n",
    "    except: \n",
    "        max_price = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of towns that we need to extract data from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "towns = filtered_df[filtered_df['ccaa'] == ccaa].town.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting data from each town"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "property = \"viviendas\"\n",
    "municipio = \"hospitalet_de_llobregat\"\n",
    "ascensor = \"-ascensor\"\n",
    "\n",
    "habitaciones = \"hab=\"+\"1\"\n",
    "baños = \"&\"+\"ban=\"+\"1\"\n",
    "maximum_price = \"pmax=\"+str(max_price)\n",
    "metros = \"m2=\"+\"50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"https://www.habitaclia.com/\"+property+ascensor+\"-\"+municipio+\".htm?\"+habitaciones+baños+maximum_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the df to which we will append the properties of the selected towns.\n",
    "name = []\n",
    "town = []\n",
    "area = []\n",
    "neighborhood = []\n",
    "geo_town = []\n",
    "features = []\n",
    "m2 = []\n",
    "n_rooms = []\n",
    "n_bath = []\n",
    "price_m2 = []\n",
    "description = []\n",
    "price = []\n",
    "opportunity = []\n",
    "price_reduction = []\n",
    "opportunity = []\n",
    "last_update = []\n",
    "url = []\n",
    "lift = []\n",
    "\n",
    "x = min(len(name), len(town), len(area), len(neighborhood), len(geo_town), len(description), len(price), len(last_update), len(url), len(lift))\n",
    "dct = {'name': name[:x], 'town': town[:x], 'area': area[:x], 'neighborhood': neighborhood[:x], 'geo_town':geo_town[:x],'m2': m2[:x], 'n_rooms': n_rooms[:x], 'n_bath': n_bath[:x], 'price_m2': price_m2[:x] ,'price': price[:x], 'price_reduction': price_reduction[:x], 'opportunity':opportunity[:x], 'last_update': last_update[:x],  'description': description[:x], 'url':url[:x], 'lift': lift[:x]}\n",
    "df = pd.DataFrame.from_dict(dct)\n",
    "\n",
    "# Pulling properties from each town in the previously defined list:\n",
    "\n",
    "for t in towns:\n",
    "    \n",
    "    # Getting the number of properties for that town to see how many pages do we need to scrape.\n",
    "    url = \"https://www.habitaclia.com/\"+property+\"-\"+t+\".htm?\"+maximum_price\n",
    "    r = requests.get(url)\n",
    "    r.status_code\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        total_results = int(soup.find('h2', attrs={'class': 'f-right'}).find('span').get_text().replace(\".\",\"\"))\n",
    "        pages = range(int(math.floor(total_results/16))+1)\n",
    "        properties = []\n",
    "\n",
    "        # Adding all the properties listed in each page to the list.\n",
    "        for p in pages:\n",
    "            sleep(randint(1,3))\n",
    "            url = \"https://www.habitaclia.com/\"+property+\"-\"+t+\"-\"+str(p)+\".htm?\"+maximum_price\n",
    "            try:\n",
    "                r = requests.get(url)\n",
    "                soup = BeautifulSoup(r.content, 'html.parser')\n",
    "                properties += soup.find_all('div', attrs={'class': 'list-item-info'})\n",
    "                del properties[-1] # Last item is an ad\n",
    "            except:\n",
    "                print('Error on page', p)\n",
    "                print('town: ', t, \" page: \", p, \"url: \", url)\n",
    "\n",
    "        # Creating a list for each piece of information I want to extract from each property.\n",
    "        name = []\n",
    "        town = []\n",
    "        area = []\n",
    "        neighborhood = []\n",
    "        geo_town = []\n",
    "        features = []\n",
    "        m2 = []\n",
    "        n_rooms = []\n",
    "        n_bath = []\n",
    "        price_m2 = []\n",
    "        description = []\n",
    "        price = []\n",
    "        opportunity = []\n",
    "        price_reduction = []\n",
    "        opportunity = []\n",
    "        last_update = []\n",
    "        url = []\n",
    "        lift = []\n",
    "\n",
    "        # Getting the information from each property.\n",
    "        for i,properties in enumerate(properties):\n",
    "            #print(i)\n",
    "            # Each feature is set as empty prior to being defined. This way we avoid errors when a feature is not available for a certain property.\n",
    "            name_temp = \"\"\n",
    "            town_temp = \"\"\n",
    "            area_temp = \"\"\n",
    "            neighborhood_temp = \"\"\n",
    "            geo_town_temp = \"\"\n",
    "            m2_temp = \"\"\n",
    "            n_rooms_temp = \"\"\n",
    "            n_bath_temp = \"\"\n",
    "            price_m2_temp = \"\"\n",
    "            price_temp = \"\"\n",
    "            opportunity_temp = \"\"\n",
    "            price_reduction_temp = \"\"\n",
    "            description_temp = \"\"\n",
    "            last_update_temp = \"\"\n",
    "            url_temp = \"\"\n",
    "            lift_temp = \"\"\n",
    "\n",
    "            # other_location enables us to differ between listed properties vs suggested properties, which appear when there are very few properties for one town. We want to avoid them as they are nearby properties not belonging to our target town.\n",
    "            other_location = properties.find('span', attrs={'class': 'ady-relationship'})\n",
    "            if other_location is None:\n",
    "                other_locations_properties = \"\"\n",
    "            else: \n",
    "                #print(i)\n",
    "                other_locations_properties = other_location.get_text(strip=True).find('Se encuentra en')\n",
    "\n",
    "            # Now I am skipping all the properties that are suggested so as to not append them to the df.\n",
    "            if other_locations_properties == 0:\n",
    "                pass\n",
    "            else:\n",
    "                try:\n",
    "                    # Extracting the features of a property and saving them in a temporary variable.\n",
    "                    name_temp = properties.find('h3', attrs={'class': 'list-item-title'}).get_text(strip=True)\n",
    "                    town_temp = properties.find('p', attrs={'class': 'list-item-location'}).get_text(strip=True).split(\"-\",1)[0].strip().replace(\"Ver mapa\",\"\")\n",
    "                    area_temp = properties.find('p', attrs={'class': 'list-item-location'}).get_text(strip=True).replace('/','-').strip().replace(\"Ver mapa\",\"\").split(\"-\",1)[0]\n",
    "                    neighborhood_temp = properties.find('p', attrs={'class': 'list-item-location'}).get_text(strip=True).replace('/','-').strip().replace(\"Ver mapa\",\"\").split(\"-\",1)[1].strip()\n",
    "                    geo_town_temp = t\n",
    "                    m2_temp = nfs.get_nums(properties.find('p', attrs={'class': 'list-item-feature'}).get_text(strip=True).split(\"-\")[0])[0] \n",
    "                    n_rooms_temp = nfs.get_nums(properties.find('p', attrs={'class': 'list-item-feature'}).get_text(strip=True).split(\"-\")[1])[0]\n",
    "                    n_bath_temp = nfs.get_nums(properties.find('p', attrs={'class': 'list-item-feature'}).get_text(strip=True).split(\"-\")[2])[0] \n",
    "                    price_m2_temp = nfs.get_nums(properties.find('p', attrs={'class': 'list-item-feature'}).get_text(strip=True).split(\"-\")[3])[0] \n",
    "                    raw_price_temp = properties.find('article', attrs={'class': 'list-item-price'}).get_text()\n",
    "                    if search(\"Oportunidad\", raw_price_temp):\n",
    "                        if search(\"ha bajado\", raw_price_temp): \n",
    "                            price_temp = nfs.get_nums((properties.find('article', attrs={'class': 'list-item-price'}).get_text()).replace(\".\",\"\"))[0]\n",
    "                            price_reduction_temp = nfs.get_nums((properties.find('article', attrs={'class': 'list-item-price'}).get_text()).replace(\".\",\"\"))[1]\n",
    "                            opportunity_temp = \"yes\"\n",
    "                        else:\n",
    "                            price_temp = nfs.get_nums((properties.find('article', attrs={'class': 'list-item-price'}).get_text()).replace(\".\",\"\"))[0]\n",
    "                            price_reduction_temp = \"0\"\n",
    "                            opportunity_temp = \"yes\"\n",
    "                    elif search(\"ha bajado\", raw_price_temp):\n",
    "                        price_temp = nfs.get_nums((properties.find('article', attrs={'class': 'list-item-price'}).get_text()).replace(\".\",\"\"))[0]\n",
    "                        price_reduction_temp = nfs.get_nums((properties.find('article', attrs={'class': 'list-item-price'}).get_text()).replace(\".\",\"\"))[1]      \n",
    "                        opportunity_temp = \"no\"\n",
    "                    else: \n",
    "                        price_temp = nfs.get_nums((properties.find('article', attrs={'class': 'list-item-price'}).get_text()).replace(\".\",\"\"))[0]\n",
    "                        price_reduction_temp = \"0\"\n",
    "                        opportunity_temp = \"no\"\n",
    "                    description_temp = properties.find('p', attrs={'class': 'list-item-description'}).get_text(strip=True)\n",
    "                    last_update_temp = nfs.get_nums(properties.find('span', attrs={'class': 'list-item-date'}).get_text(strip=True))\n",
    "                    url_temp = properties.find('h3', attrs={'class': 'list-item-title'}).find('a').get('href')\n",
    "                    lift_temp = \"\"\n",
    "                    \n",
    "                    # Appending temporary variables features to their corresponding list.\n",
    "                    name.append(name_temp)\n",
    "                    town.append(town_temp)\n",
    "                    area.append(area_temp)\n",
    "                    neighborhood.append(neighborhood_temp)\n",
    "                    geo_town.append(geo_town_temp)\n",
    "                    m2.append(m2_temp)\n",
    "                    n_rooms.append(n_rooms_temp)\n",
    "                    n_bath.append(n_bath_temp)\n",
    "                    price_m2.append(price_m2_temp)\n",
    "                    price.append(price_temp)\n",
    "                    opportunity.append(opportunity_temp)\n",
    "                    price_reduction.append(price_reduction_temp)\n",
    "                    description.append(description_temp)\n",
    "                    last_update.append(last_update_temp)\n",
    "                    url.append(url_temp)\n",
    "                    lift.append(lift_temp)\n",
    "\n",
    "                except:\n",
    "                    # In case we may encounter an error, we print the features of each property to find the bug.\n",
    "                    '''\n",
    "                    print('------------------------------------')\n",
    "                    print('nombre: ', name_temp)\n",
    "                    print('town_temp: ', town_temp)\n",
    "                    print('area_temp: ', area_temp)\n",
    "                    print('m2_temp: ', m2_temp)\n",
    "                    print('n_rooms_temp: ', n_rooms_temp)\n",
    "                    print('n_bath_temp: ', n_bath_temp)\n",
    "                    print('price_m2_temp: ', price_m2_temp)\n",
    "                    print('price_temp: ', price_temp)\n",
    "                    print('opportunity_temp: ', opportunity_temp)\n",
    "                    print('price_reduction_temp: ', price_reduction_temp)\n",
    "                    print('description_temp: ', description_temp)\n",
    "                    print('last_update_temp: ', last_update_temp)\n",
    "                    print('url_temp: ', url_temp)\n",
    "                    print('------------------------------------')\n",
    "                    '''\n",
    "        \n",
    "        x_town = min(len(name), len(town), len(area), len(neighborhood), len(geo_town), len(description), len(price), len(last_update), len(url), len(lift))\n",
    "        dct_town = {'name': name[:x_town], 'town': town[:x_town], 'area': area[:x_town], 'neighborhood': neighborhood[:x_town], 'geo_town':geo_town[:x_town],'m2': m2[:x_town], 'n_rooms': n_rooms[:x_town], 'n_bath': n_bath[:x_town], 'price_m2': price_m2[:x_town] ,'price': price[:x_town], 'price_reduction': price_reduction[:x_town], 'opportunity':opportunity[:x_town], 'last_update': last_update[:x_town],  'description': description[:x_town], 'url':url[:x_town], 'lift': lift[:x_town]}\n",
    "        df_town = pd.DataFrame.from_dict(dct_town)\n",
    "        df = df.append(df_town, ignore_index = True)\n",
    "        \n",
    "        #Cleaning the final df\n",
    "        #df = df[~df['description'].str.contains('nuda|sin cedula|sin cédula')]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output from the web scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6863, 16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>town</th>\n",
       "      <th>area</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>geo_town</th>\n",
       "      <th>m2</th>\n",
       "      <th>n_rooms</th>\n",
       "      <th>n_bath</th>\n",
       "      <th>price_m2</th>\n",
       "      <th>price</th>\n",
       "      <th>price_reduction</th>\n",
       "      <th>opportunity</th>\n",
       "      <th>last_update</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Piso  en  Plaça sa boada, 35. Oportunidad en e...</td>\n",
       "      <td>Arenys de Mar</td>\n",
       "      <td>Arenys de Mar</td>\n",
       "      <td>Centre</td>\n",
       "      <td>arenys_de_mar</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.898</td>\n",
       "      <td>94900.0</td>\n",
       "      <td>100</td>\n",
       "      <td>yes</td>\n",
       "      <td>[]</td>\n",
       "      <td>Tenemos en exclusiva esta vivienda visitas con...</td>\n",
       "      <td>https://www.habitaclia.com/comprar-piso-oportu...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apartamento  Carrer avall (d´). Apartamento en...</td>\n",
       "      <td>Arenys de Mar</td>\n",
       "      <td>Arenys de Mar</td>\n",
       "      <td>Centre</td>\n",
       "      <td>arenys_de_mar</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.171</td>\n",
       "      <td>89000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Disseny i habitatge les presenta este fantásti...</td>\n",
       "      <td>https://www.habitaclia.com/comprar-apartamento...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Piso  Carrer camí de la pietat. Piso economico...</td>\n",
       "      <td>Arenys de Mar</td>\n",
       "      <td>Arenys de Mar</td>\n",
       "      <td>Centre</td>\n",
       "      <td>arenys_de_mar</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.774</td>\n",
       "      <td>88700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>[3]</td>\n",
       "      <td>Piso de 50 m2, con comedor de 15 m2, cocina in...</td>\n",
       "      <td>https://www.habitaclia.com/comprar-piso-econom...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name           town  \\\n",
       "0  Piso  en  Plaça sa boada, 35. Oportunidad en e...  Arenys de Mar   \n",
       "1  Apartamento  Carrer avall (d´). Apartamento en...  Arenys de Mar   \n",
       "2  Piso  Carrer camí de la pietat. Piso economico...  Arenys de Mar   \n",
       "\n",
       "             area neighborhood       geo_town    m2  n_rooms  n_bath  \\\n",
       "0  Arenys de Mar        Centre  arenys_de_mar  50.0      3.0     1.0   \n",
       "1  Arenys de Mar        Centre  arenys_de_mar  41.0      1.0     1.0   \n",
       "2  Arenys de Mar        Centre  arenys_de_mar  50.0      3.0     1.0   \n",
       "\n",
       "   price_m2    price price_reduction opportunity last_update  \\\n",
       "0     1.898  94900.0             100         yes          []   \n",
       "1     2.171  89000.0               0          no         [3]   \n",
       "2     1.774  88700.0               0          no         [3]   \n",
       "\n",
       "                                         description  \\\n",
       "0  Tenemos en exclusiva esta vivienda visitas con...   \n",
       "1  Disseny i habitatge les presenta este fantásti...   \n",
       "2  Piso de 50 m2, con comedor de 15 m2, cocina in...   \n",
       "\n",
       "                                                 url lift  \n",
       "0  https://www.habitaclia.com/comprar-piso-oportu...       \n",
       "1  https://www.habitaclia.com/comprar-apartamento...       \n",
       "2  https://www.habitaclia.com/comprar-piso-econom...       "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.merge(geo_data, left_on='geo_town', right_on='town', how='left')\n",
    "df1 = df1.drop([\"town_x\", \"town_y\", \"n_properties\"], axis=1)\n",
    "df1 = df1.loc[:, ~df1.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericals = ['m2', 'n_rooms', 'n_bath', 'price_m2', 'price', 'price_reduction', 'last_update']\n",
    "\n",
    "def anytype_to_numerical(df, columns = []):\n",
    "    for c in columns:\n",
    "        if df[c].dtypes == 'float64':\n",
    "            df[c] = df[c].astype(int)\n",
    "\n",
    "def clean_last_update():\n",
    "    for i,n in enumerate(df1['last_update']):\n",
    "        try:\n",
    "            df1['last_update'][i] = df1['last_update'][i][0]\n",
    "        except:\n",
    "            df1['last_update'][i] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "anytype_to_numerical(df1, columns = numericals)\n",
    "clean_last_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= df1[df1['price']<int(max_price)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['lift'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4497, 17)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting info about lifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = {'name': [],\n",
    "       'town':[],\n",
    "       'area': [],\n",
    "       'neighborhood': [],\n",
    "       'geo_town': [],\n",
    "       'm2': [],\n",
    "       'n_rooms': [],\n",
    "       'n_bath': [],\n",
    "       'price_m2': [],\n",
    "       'description': [],\n",
    "       'price': [],\n",
    "       'opportunity': [],\n",
    "       'price_reduction': [],\n",
    "       'last_update': [],\n",
    "       'url': [],\n",
    "       'lift': []}\n",
    "# Data Scraping begins\n",
    "for t in towns:\n",
    "    url = \"https://www.habitaclia.com/\"+property+\"-\"+\"viviendas-ascensor\"+\"-\"+t+\".htm?\"+maximum_price\n",
    "    r = requests.get(url)\n",
    "    r.status_code\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    try:\n",
    "        # Getting the number of properties for that town to see how many pages do we need to scrape.\n",
    "        total_results = int(soup.find('h2', attrs={'class': 'f-right'}).find('span').get_text().replace(\".\",\"\"))\n",
    "        pages = range(int(math.floor(total_results/16))+1)\n",
    "        properties = []\n",
    "        # Adding all the properties listed in each page to the list.\n",
    "        for p in pages:\n",
    "            sleep(randint(2,3))\n",
    "            url = \"https://www.habitaclia.com/\"+property+\"-\"+\"viviendas-ascensor\"+\"-\"+t+\"-\"+str(p)+\".htm?\"+maximum_price\n",
    "            try:\n",
    "                r = requests.get(url)\n",
    "                soup = BeautifulSoup(r.content, 'html.parser')\n",
    "                properties += soup.find_all('div', attrs={'class': 'list-item-info'})\n",
    "                del properties[-1] # Last item is an ad\n",
    "            except:\n",
    "                print('Error on page', p)\n",
    "                print('town: ', t, \" page: \", p, \"url: \", url)\n",
    "                \n",
    "        # Getting the information from each property.\n",
    "        for i,properties in enumerate(properties):  \n",
    "            dct_2 = {}\n",
    "            dct_3 = {}\n",
    "            for k, v in dct.items():\n",
    "                k_temp = str(k)+'_temp'\n",
    "                dct_2[k] = k_temp\n",
    "            for k,v in dct_2.items():\n",
    "                dct_3[v] = \"\"\n",
    "            \n",
    "            # other_location enables us to differ between listed properties vs suggested properties, which appear when there are very few properties for one town. We want to avoid them as they are nearby properties not belonging to our target town.\n",
    "            other_location = properties.find('span', attrs={'class': 'ady-relationship'})\n",
    "            if other_location is None:\n",
    "                other_locations_properties = \"\"\n",
    "            else: \n",
    "                other_locations_properties = other_location.get_text(strip=True).find('Se encuentra en')\n",
    "\n",
    "            # Now I am skipping all the properties that are suggested so as to not append them to the df.\n",
    "            if other_locations_properties == 0:\n",
    "                pass\n",
    "            else:\n",
    "                try:\n",
    "                    # Extracting the features of a property and saving them in a temporary variable.\n",
    "                    dct_3['name_temp'] = properties.find('h3', attrs={'class': 'list-item-title'}).get_text(strip=True)\n",
    "                    dct_3['town_temp'] = properties.find('p', attrs={'class': 'list-item-location'}).get_text(strip=True).split(\"-\",1)[0].strip().replace(\"Ver mapa\",\"\")\n",
    "                    dct_3['area_temp'] = properties.find('p', attrs={'class': 'list-item-location'}).get_text(strip=True).replace('/','-').strip().replace(\"Ver mapa\",\"\").split(\"-\",1)[0]\n",
    "                    dct_3['neighborhood_temp'] = properties.find('p', attrs={'class': 'list-item-location'}).get_text(strip=True).replace('/','-').strip().replace(\"Ver mapa\",\"\").split(\"-\",1)[1].strip()\n",
    "                    dct_3['geo_town_temp'] = t\n",
    "                    dct_3['m2_temp'] = nfs.get_nums(properties.find('p', attrs={'class': 'list-item-feature'}).get_text(strip=True).split(\"-\")[0])[0] \n",
    "                    dct_3['n_rooms_temp'] = nfs.get_nums(properties.find('p', attrs={'class': 'list-item-feature'}).get_text(strip=True).split(\"-\")[1])[0]\n",
    "                    dct_3['n_bath_temp'] = nfs.get_nums(properties.find('p', attrs={'class': 'list-item-feature'}).get_text(strip=True).split(\"-\")[2])[0] \n",
    "                    dct_3['price_m2_temp'] = nfs.get_nums(properties.find('p', attrs={'class': 'list-item-feature'}).get_text(strip=True).split(\"-\")[3])[0] \n",
    "                    dct_3['raw_price_temp'] = properties.find('article', attrs={'class': 'list-item-price'}).get_text()\n",
    "                    \n",
    "                    if search(\"Oportunidad\", dct_3['raw_price_temp']):\n",
    "                        if search(\"ha bajado\", dct_3['raw_price_temp']): \n",
    "                            dct_3['price_temp'] = nfs.get_nums((properties.find('article', attrs={'class': 'list-item-price'}).get_text()).replace(\".\",\"\"))[0]\n",
    "                            dct_3['price_reduction_temp'] = nfs.get_nums((properties.find('article', attrs={'class': 'list-item-price'}).get_text()).replace(\".\",\"\"))[1]\n",
    "                            dct_3['opportunity_temp'] = \"yes\"\n",
    "                        else:\n",
    "                            dct_3['price_temp'] = nfs.get_nums((properties.find('article', attrs={'class': 'list-item-price'}).get_text()).replace(\".\",\"\"))[0]\n",
    "                            dct_3['price_reduction_temp'] = \"0\"\n",
    "                            dct_3['opportunity_temp'] = \"yes\"\n",
    "                    elif search(\"ha bajado\", dct_3['raw_price_temp']):\n",
    "                        dct_3['price_temp'] = nfs.get_nums((properties.find('article', attrs={'class': 'list-item-price'}).get_text()).replace(\".\",\"\"))[0]\n",
    "                        dct_3['price_reduction_temp'] = nfs.get_nums((properties.find('article', attrs={'class': 'list-item-price'}).get_text()).replace(\".\",\"\"))[1]      \n",
    "                        dct_3['opportunity_temp'] = \"no\"\n",
    "                    else: \n",
    "                        dct_3['price_temp'] = nfs.get_nums((properties.find('article', attrs={'class': 'list-item-price'}).get_text()).replace(\".\",\"\"))[0]\n",
    "                        dct_3['price_reduction_temp'] = \"0\"\n",
    "                        dct_3['opportunity_temp'] = \"no\"\n",
    "                    dct_3['description_temp'] = properties.find('p', attrs={'class': 'list-item-description'}).get_text(strip=True)\n",
    "                    dct_3['last_update_temp'] = nfs.get_nums(properties.find('span', attrs={'class': 'list-item-date'}).get_text(strip=True))\n",
    "                    dct_3['url_temp'] = properties.find('h3', attrs={'class': 'list-item-title'}).find('a').get('href')\n",
    "                    dct_3['lift_temp'] = 'yes'\n",
    "                    # Appending temporary variables features to their corresponding dictionary.\n",
    "                    for k,v in dct.items():\n",
    "                        temp = k+'_temp'\n",
    "                        dct[k].append(dct_3[temp])\n",
    "                    \n",
    "                except:\n",
    "                    print('error')\n",
    "        \n",
    "        x = min(map(len, dct.values()))\n",
    "        df = pd.DataFrame({k:v[:x] for k,v in dct.items()})\n",
    "        \n",
    "    except:\n",
    "        print(\"no properties found at: \", url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_lift = df_lift.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2327, 16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_lift.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_lift = df1_lift.merge(geo_data, left_on='geo_town', right_on='town', how='left')\n",
    "df1_lift = df1_lift.drop([\"town_x\", \"town_y\", \"n_properties\"], axis=1)\n",
    "df1_lift = df1_lift.loc[:, ~df1_lift.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericals = ['m2', 'n_rooms', 'n_bath', 'price_m2', 'price', 'price_reduction', 'last_update']\n",
    "\n",
    "def anytype_to_numerical(df, columns = []):\n",
    "    for c in columns:\n",
    "        if df[c].dtypes == 'float64':\n",
    "            df[c] = df[c].astype(int)\n",
    "\n",
    "def clean_last_update():\n",
    "    for i,n in enumerate(df1_lift['last_update']):\n",
    "        try:\n",
    "            df1_lift['last_update'][i] = df1_lift['last_update'][i][0]\n",
    "        except:\n",
    "            df1_lift['last_update'][i] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "anytype_to_numerical(df1_lift, columns = numericals)\n",
    "clean_last_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_lift= df1_lift[df1_lift['price']<int(max_price)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1335, 17)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_lift.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_names_with_lift = list(df1_lift['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df1.combine_first(df1_lift)\n",
    "final_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5126, 17)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data about the floor of each property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.insert(1, 'floor', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>floor</th>\n",
       "      <th>area</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>geo_town</th>\n",
       "      <th>m2</th>\n",
       "      <th>n_rooms</th>\n",
       "      <th>n_bath</th>\n",
       "      <th>price_m2</th>\n",
       "      <th>price</th>\n",
       "      <th>price_reduction</th>\n",
       "      <th>opportunity</th>\n",
       "      <th>last_update</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>lift</th>\n",
       "      <th>province</th>\n",
       "      <th>ccaa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apartamento  Carrer avall (d´). Apartamento en...</td>\n",
       "      <td></td>\n",
       "      <td>Arenys de Mar</td>\n",
       "      <td>Centre</td>\n",
       "      <td>arenys_de_mar</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>89000</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>Disseny i habitatge les presenta este fantásti...</td>\n",
       "      <td>https://www.habitaclia.com/comprar-apartamento...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>barcelona</td>\n",
       "      <td>cataluña</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Piso  Carrer camí de la pietat. Piso economico...</td>\n",
       "      <td></td>\n",
       "      <td>Arenys de Mar</td>\n",
       "      <td>Centre</td>\n",
       "      <td>arenys_de_mar</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>88700</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>Piso de 50 m2, con comedor de 15 m2, cocina in...</td>\n",
       "      <td>https://www.habitaclia.com/comprar-piso-econom...</td>\n",
       "      <td>yes</td>\n",
       "      <td>barcelona</td>\n",
       "      <td>cataluña</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Piso  Carrer de la independència. Oportunidad ...</td>\n",
       "      <td></td>\n",
       "      <td>Badalona</td>\n",
       "      <td>Bufalà</td>\n",
       "      <td>badalona</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79000</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>CÓD. 1689 ¡¡¡OPORTUNIDAD!! LOFT en venta de 77...</td>\n",
       "      <td>https://www.habitaclia.com/comprar-piso-oportu...</td>\n",
       "      <td>yes</td>\n",
       "      <td>barcelona</td>\n",
       "      <td>cataluña</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name floor            area  \\\n",
       "0  Apartamento  Carrer avall (d´). Apartamento en...        Arenys de Mar    \n",
       "1  Piso  Carrer camí de la pietat. Piso economico...        Arenys de Mar    \n",
       "2  Piso  Carrer de la independència. Oportunidad ...             Badalona    \n",
       "\n",
       "  neighborhood       geo_town  m2  n_rooms  n_bath  price_m2  price  \\\n",
       "0       Centre  arenys_de_mar  41        1       1         2  89000   \n",
       "1       Centre  arenys_de_mar  50        3       1         1  88700   \n",
       "2       Bufalà       badalona  77        1       1         1  79000   \n",
       "\n",
       "  price_reduction opportunity last_update  \\\n",
       "0               0          no           3   \n",
       "1               0          no           3   \n",
       "2               0          no           0   \n",
       "\n",
       "                                         description  \\\n",
       "0  Disseny i habitatge les presenta este fantásti...   \n",
       "1  Piso de 50 m2, con comedor de 15 m2, cocina in...   \n",
       "2  CÓD. 1689 ¡¡¡OPORTUNIDAD!! LOFT en venta de 77...   \n",
       "\n",
       "                                                 url lift   province      ccaa  \n",
       "0  https://www.habitaclia.com/comprar-apartamento...  NaN  barcelona  cataluña  \n",
       "1  https://www.habitaclia.com/comprar-piso-econom...  yes  barcelona  cataluña  \n",
       "2  https://www.habitaclia.com/comprar-piso-oportu...  yes  barcelona  cataluña  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_underground_floor = ['sótano', 'sotano', 'semi sotano', 'semi sótano', 'semisotano', 'semisótano']\n",
    "lst_ground_floor = ['bajo', 'bajos']\n",
    "lst_first_floor = ['primera planta', 'primer piso', 'primero']\n",
    "lst_second_floor = ['segunda planta', 'segundo piso', 'segundo']\n",
    "lst_third_floor = ['tercera planta', 'tercer piso', 'tercero']\n",
    "lst_fourth_floor = ['cuarta planta', 'cuarto piso']\n",
    "lst_fifth_floor = ['quinta planta', 'quinto piso', 'quinto']\n",
    "lst_sixth_floor = ['sexta planta', 'sexto piso', 'sexto']\n",
    "lst_seventh_floor = ['séptima planta', 'séptimo piso', 'séptimo', 'septima planta', 'septimo piso', 'septimo']\n",
    "lst_eighth_floor = ['octava planta', 'octavo piso', 'octavo']\n",
    "lst_ninth_floor = ['novena planta', 'noveno piso', 'noveno']\n",
    "lst_tenth_floor = ['décima planta', 'décimo piso', 'décimo', 'décima planta', 'décimo piso', 'décimo']\n",
    "\n",
    "list_floors = [lst_underground_floor, \n",
    "               lst_ground_floor,\n",
    "               lst_first_floor,\n",
    "               lst_second_floor,\n",
    "               lst_third_floor,\n",
    "               lst_fourth_floor,\n",
    "               lst_fifth_floor,\n",
    "               lst_sixth_floor,\n",
    "               lst_seventh_floor,\n",
    "               lst_eighth_floor,\n",
    "               lst_ninth_floor,\n",
    "               lst_tenth_floor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Floor data in the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in list_floors:\n",
    "    find_floor(final_df, \n",
    "               column = 'description', \n",
    "               key_words = l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Floor data from urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3700\n",
      "3800\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "5000\n",
      "5100\n"
     ]
    }
   ],
   "source": [
    "get_lift_from_property_url(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df1 = final_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_floors(final_df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the scraped df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.now().strftime('%Y.%m.%d')\n",
    "final_df1.to_csv(path_or_buf = '/Users/ignaciolorenzoqueralt/Documents/Ironhack/Final Project/properties/sale/'+today+'_'+ccaa+'_'+str(max_price)+'_'+str(num_properties_per_town)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack_1",
   "language": "python",
   "name": "ironhack_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
